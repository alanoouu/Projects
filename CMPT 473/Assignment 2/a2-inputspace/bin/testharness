#!/bin/zsh

#  testharness
#  Assignment 2
#
#  Created by mpuchkov on 2020-02-01.
#  Copyright © 2020 Maxim Puchkov. All rights reserved.


#MARK: - TestHarness usage
DEFAULT_USAGE="zsh bin/testharness" # Run from Project's root directory
USAGE="testharness [-h] [-b] [-d /dir/TestData] [-p /bin/csv2json]\n\n\
    -h, --help                          - Print script usage.\n\
    -b, --brief                         - Output only whether files differ.\n\
    -n, --nopts                         - Do not show process invocation options.\n\
    -q, --quiet                         - Suppress some output.\n\
    -d, --data /dir/TestData            - Path to TestData directory.\n\
    -p, --program /bin/csv2json         - Path to program under test.\n\
    -r, --rename 'old_name' 'new_name'  - Rename test files from 'old_name' to 'new_name'.
    "

# libtest: Text style, quiet commands, diff
src_dir=${0%/*}
source $src_dir/libtest         # Prefix: _

# Options
setopt nullglob 2>/dev/null     # zsh
shopt -s nullglob 2>/dev/null   # bash
#setopt -s xtrace

# Test data directory and program to test
TEST_DATA_DIR="./TestData"      # Default: ./TestData
TEST_PROGRAM="csv2json"         # Default: csv2json
BRIEF_DIFF=0                    # Default: 0 (full side-by-side comparison)
NO_OPTIONS=0

# Directories
input_dir="$TEST_DATA_DIR/Input"             # Input
input_files_dir="$input_dir/Files"           #   CSV files
input_opts_dir="$input_dir/OptionsAndFlags"  #   -a, -b, -n, -d, -D, etc.
out_dir="$TEST_DATA_DIR/Output"              # Output
out_files_dir="$out_dir/Files"
out_msgs_dir="$out_dir/Messages"
exp_dir="$TEST_DATA_DIR/Expected"            # Expected
exp_files_dir="$exp_dir/Files"
exp_msgs_dir="$exp_dir/Messages"
#    .
#    ├── TestData
#    │   ├── Expected/
#    │   ├── Input/
#    │   └── Output/
#    └── bin
#        ├── csv2json
#        └── testharness


# List of executed commands
declare -x -a executed_commands
executed_commands=()
commands_log_file=./commands.log


# diff
SAME=$(green 'identical')
DIFF=$(red 'different')
# Test result
PASS=$(green '✔︎')
FAIL=$(red '✘')
# Indentation, space Breaks
IN="$(cyan '  >')"
IN2="$(cyan '  >>')"
BR='      '
BR2='            '
LONGBR='                                 '


#MARK: - Main Function
# Run the script from project's root:
#   zsh bin/testharness
function main() {
    echo "Automating tests..."
    show_paths          # Display paths to test folders/files
    validate_settings   # Exit if can't find required files
    cleanup             # Delete contents of Output folder
    add_missing         # Create missing folders/files if needed
    generate_output     # Run test program and save its output
    terminate_jobs      # Stop jobs that are still active
    compare             # Compare actual and expected output
    test_report         # Display number of passed/failed tests
#    write_logs          # Save executed commands in 'commands.log'
    echo "Done."
    _exit 0
}

_do_job() {
    echo "Next job: $(cyan $@)"
    $("$@") &
}

# Calls the program under test to generate
# output files and messages
function run_test_program() {
#    echo "Msg=$(yellow "P=$pipe, @1=${@:1}")"
#    echo "HI" 1&> /dev/stdout
#    read y
    _do_command $TEST_PROGRAM "$@" #| $pipe
#    _do_job $TEST_PROGRAM ${@:1} | ( $1 )
    return $?
}


# Show script usage
function print_usage() {
    echo
    echo "Usage:"
    echo "Recommended (run from Project's root):"
    echo "  $DEFAULT_USAGE"
    echo "Custom (run from anywhere):"
    echo "  $USAGE"
    echo
}
# Exit-2 if testharness option is invalid
function invalid_usage() {
    echo "$(red 'Option error.')"
    print_usage
    _exit 2
}


# Print paths to directories and program
function show_paths() {
    echo
    echo "$IN" "Directories and program:"
    echo "$BR" "TestData:  $TEST_DATA_DIR"
    echo "$BR" "Input:     $input_dir"
    echo "$BR" "Output:    $out_dir"
    echo "$BR" "Expected:  $exp_dir"
    echo "$BR" "Program:   $TEST_PROGRAM"
    echo "$BR" "Binary:    $(which $TEST_PROGRAM)"
    echo "$BR" "Log:       $commands_log_file"
    echo
}


# Exit if the script cannot find TestData
# or test program binary
function validate_settings() {
    echo "$IN" "Validating arguments..."
    _validate_data
    _validate_input_files
    _validate_program
    echo
}


# Delete all files and messages in 'Output' directory
function cleanup() {
    local i=0
    if [[ -e $out_dir ]]; then
        echo "$IN" "Removing existing output..."
        for f in $out_files_dir/*; do
            printf "$BR File \t $( _file $f )\n"
            rm $f
            i=$(( i + 1 ))
        done
        for f in $out_msgs_dir/*; do
            printf "$BR Message \t $( _file $f )\n"
            rm $f
            i=$(( i + 1 ))
        done
        echo "$IN" "Removed $i files."
        echo
    fi
}
# Create empty directories and files if needed
function add_missing() {
    if [[ ! -e $out_dir ]]; then
        echo "$IN" "Creating Output directory..."
        mkdir -p $out_dir/{Files,Messages}
        echo
    fi
    for input_file in $input_files_dir/*; do
        fname=$( _filename $input_file )
        touch $input_opts_dir/$fname.txt
        touch $exp_files_dir/$fname.json
        touch $exp_msgs_dir/$fname.txt
    done
}


# Run the program under test for each input file
function generate_output() {
    echo "$IN" "Generating output..."
    local i=0
    for input_file in $input_files_dir/*; do
        fname=$( _filename $input_file )
        unset write_to_file
        unset pipe_to_command
        unset opts
        # Read from text file in 'Input/OptionsAndFlags'
        opts_text=($( < $input_opts_dir/$fname.txt ))
        # Add input file if options don't include it
        if [[ ! (${opts_text[@]} =~ '--in' && ${opts_text[@]} =~ '-i') ]]; then
            opts_text=('--in' $input_file ${opts_text[@]})
        fi
        # Add output directory
#        if [[ ! (${opts_text[@]} =~ '--out-dir' || ${opts_text[@]} =~ '-o') ]]; then #
#             opts_text=(${opts_text[@]} '--out-dir' $out_files_dir)
#        fi

#         Parse where the output is redirected.
#        if [[ ${opts_text[@]} =~ '>' ]]; then
#            write_to_file=$(grep -i -o -E '> ((\\ )|[^ ])*' <<< ${opts_text[@]})
#            write_to_file=${write_to_file// }
#            write_to_file=${write_to_file:1}
#            opts_text=(${opts_text[@]//>})
#            opts_text=(${opts_text[@]//$write_to_file})
#        fi
#        # Parse where the output is piped.
#        if [[ ${opts_text[@]} =~ '\|' ]]; then
#            pipe_to_command=$(grep -i -o -E '\| .*$' <<< ${opts_text[@]})
##            pipe_to_command=${pipe_to_command}
#            pipe_to_command=${pipe_to_command:1}
#            opts_text=(${opts_text[@]//\|})
#            opts_text=(${opts_text[@]//$pipe_to_command})
#        fi
        
        [[ -z $write_to_file ]] && write_to_file=/dev/null
        
        # Pass options without '/" to program.
        opts=(${opts_text[@]//[\'\"]})
#        green $opts
        program_parameters=( ${opts[*]} )
        
        # Text of all options used to invoke to program.
        opts_text+=("\n$BR2")
        opts_text+=("> $write_to_file")
        opts_text+=("> $out_files_dir/$fname.json")
        opts_text+=("2>$out_msgs_dir/$fname.txt")
#        [[ -n $pipe_to_command ]] && opts_text+=("| $pipe_to_command")
        # Display file name and options (unless -o is set).
        echo "$BR" "$fname"
        if [[ $NO_OPTIONS -ne 1 ]]; then echo "$BR2" "$(grey "${opts_text[@]}")"; fi
        run_test_program "${program_parameters[@]}" > $out_files_dir/$fname.json 2>$out_msgs_dir/$fname.txt &
        
##        read y
#        if [[ -n $pipe_to_command ]]; then
#
##            green "$!. Only identifies command to pipe to: "$pipe_to_command
#        else
##            blue "$!. OK, writes to: $write_to_file"
#            run_test_program ${program_parameters[@]} > ${write_to_file:-/dev/null} > $out_files_dir/$fname.json 2>$out_msgs_dir/$fname.txt &
#        fi
#
        i=$(( i + 1 ))
    done
    echo "$IN" "Generated $i files and $i messages."
    echo
}

# Terminate jobs that are active for too long
function terminate_jobs() {
    if [[ countjobs != '0' ]]; then
        killall -SIGTERM $TEST_PROGRAM
    fi
}
#echo "$(yellow 'Warning:') program under test"\
    "stopped responding and was terminated."\
    "(143, SIGTERM)."
#echo

# Find differences between expected output and actual output
function compare() {
    echo "$IN" "Comparing differences with expected output..."
    echo
    
    # Number of
    local i=0       # compared files
    num_df=0        # different files
    num_dm=0        # different messages
    num_passed=0    # passed tests
    num_failed=0    # failed tests
    
    # Comparison summary (lines)
    declare -a summary
    summary+=("$( printf "$BR   %-25s %-25s %-20s" "Input File:" "Kind:" "File:           Message:" )\n")
    
    for expected_output in $exp_files_dir/*; do
        #MARK: Brief Diff
        # File names and extensions
        fname=$( _filename $expected_output )
        f=$( _file $expected_output )
        finfo=$( _fileinfo $input_files_dir/$fname* )
        finfo=${finfo%,.)*}
        m="$fname.txt"
        # Compare expected and actual output files
        _quiet _is_diff_file $f
        if [[ $? -eq 0 ]];
            then df="$SAME";
            else df="$DIFF"; num_df=$(( $num_df + 1 ));
        fi
        # Compare expected and actual output messages
        _quiet _is_diff_msg $m
        if [[ $? -eq 0 ]];
            then dm="$SAME";
            else dm="$DIFF"; num_dm=$(( $num_dm + 1 ));
        fi

        # Test passes if both file and message are the same as expected
        if [[ $df = "$SAME" ]] && [[ $dm = "$SAME" ]]; then
            num_passed=$(( $num_passed + 1 ))
            test_status="$PASS"
            heading="$(green $fname) $test_status"
        else
            num_failed=$(( $num_failed + 1 ))
            test_status="$FAIL"
            heading="$(redbg $fname)$(redbg ' - TEST FAILED')"
        fi
        
        # Generate test summary to display after all tests
        result=$( printf "$BR %s %-25s %-25s %-20s   |   %-20s" "$test_status" "${fname:0:22}" "${finfo:0:22}" "$df" "$dm" )
        summary+=("$result\n")
        i=$(( i + 2 ))
        
        #MARK: Full Diff
        # Skip if -b|--brief flag is set
        if [[ $BRIEF_DIFF -eq 1 ]]; then continue; fi
        # Display detailed side-by-side comparison for each test file
        echo "$heading"
        echo "$IN2" "$(underline 'expected output file')" "$LONGBR" "$IN2" "$(underline 'actual output file')"
        _diff_file_content $f
        echo;
        echo "$IN2" "$(underline 'expected message')    " "$LONGBR" "$IN2" "$(underline 'actual message')"
        _diff_msg_content $m
        echo; echo; echo;
    done
    
    # Display brief summary
    echo
    echo "$IN" "File comparison summary"
    printf " ${summary[*]}"
    echo "$IN" "Compared $i files: $(red $num_df) files and $(red $num_dm) messages are different from expected."
    echo
}


# Write calls to 'TEST_PROGRAM' and 'diff' to commands.log
function write_logs() {
    echo "# \t Status \t Full Command" > $commands_log_file
    local i=1
    for c in $executed_commands; do
        echo "$i.\t $c" >> $commands_log_file
        i=$(( i + 1 ))
    done
    echo "Test commands logged in 'commands.log'."
}
# Display number and percentage of passed/failed tests
function test_report() {
    local total=$(( $num_passed + $num_failed ))
    local f=$(( $num_failed * 100 / $total ))
    local p=$(( 100 - $f ))
    echo "$IN" "Number of tests ran: $total"
    echo "$BR" "$(green $num_passed) out of $total ($(green $p'%')) tests $(green 'PASSED') $PASS"
    echo "$BR" "$(red $num_failed) out of $total ($(red $f'%')) tests $(red 'FAILED') $FAIL"
    echo
}


# Program options
while [[ "$1" =~ ^- ]] && [[ ! "$1" == "--" ]]; do
    case "$1" in
        # TestHarness help
        '-h' | '--help')
            print_usage
            _exit 0
            ;;
        # Do not compare each file side-by-side
        '-b' | '--brief')
            BRIEF_DIFF=1
            echo "Enabled $(cyan 'brief difference report')."
            ;;
       '-n' | '--nopts')
            NO_OPTIONS=1
            echo "Enabled $(cyan 'no options report')."
            ;;
       '-q' | '--quiet')
#            QUIET=1
            BRIEF_DIFF=1
            NO_OPTIONS=1
            echo "Enabled $(cyan 'quiet report')."
            ;;
        
        # Path to TestData directory
        '-d' | '--data')
            if [[ -z "$2" ]]; then invalid_usage; fi
            shift
            TEST_DATA_DIR="$1"
            echo "TestData directory is set to $(cyan $TEST_DATA_DIR)."
            ;;
        # Path to program under test
        '-p' | '--program')
            if [[ -z "$2" ]]; then invalid_usage; fi
            shift
            TEST_PROGRAM="$1"
            echo "Test program is set to $(cyan $TEST_PROGRAM)."
            ;;
        # Rename test files
        '-r' | '--rename')
            if [[ -z "$2" || -z "$3" ]]; then invalid_usage; fi
            shift
            # From
            old_name=$( _filename "$1" )
            if [[ ! $( find $input_files_dir -name $old_name'*' ) ]]; then
                echo "$(red "Test file $old_name does not exist.")"
                _exit 1
            fi
            shift
            # To
            new_name=$( _filename "$1" )
            if [[ $( find $input_files_dir -name $new_name'*' )  ]]; then
                echo "$(red "Test file $new_name already exists.")"
                _exit 1
            fi
            # Rename
            echo "Renamed $(red $old_name) to $(green $new_name):"
            for old_file in $TEST_DATA_DIR/{Input/{Files,OptionsAndFlags},Expected}/**/$old_name*; do
                ext=$( _fileext $old_file )
                dir=$( _filedir $old_file )
                mv $old_file $dir/$new_name.$ext
                echo "\t$dir/$(red $old_name'.'$ext) $(green '--->') $dir/$(green $new_name'.'$ext)"
                done;
            _exit 0
            ;;
        
        *)
            invalid_usage
            ;;
    esac
    shift
done




time main "$@"
